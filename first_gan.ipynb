{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f137abb24f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    return image_grid\n",
    "    # plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "class Generator(nn.Module):\n",
    "    # z_dim : dimension of noise, scalar\n",
    "    # im_dim: dimension of images: image(28x28 = 784)\n",
    "    # hidden_dim: output of hidden layer, s scalar\n",
    "    def __init__(self, z_dim = 10, im_dim = 784, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim*2),\n",
    "            get_generator_block(hidden_dim*2, hidden_dim*4),\n",
    "            get_generator_block(hidden_dim*4, hidden_dim*8),\n",
    "            nn.Linear(hidden_dim*8, im_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "    \n",
    "    def get_model_gennerator(self):\n",
    "        return self.gen\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n, z_dim, device='cpu'):\n",
    "    # Create noise\n",
    "    # n - the number of samples to generate\n",
    "    # z_dim - the dimension of noise vector, scalar\n",
    "    return torch.randn(n, z_dim, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dis_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "class Discriminator(nn.Module):\n",
    "    # dimension of images: 28x28 = 784\n",
    "    def __init__(self, im_dim = 784, hidden_dim = 128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            get_dis_block(im_dim, hidden_dim*4),\n",
    "            get_dis_block(hidden_dim*4, hidden_dim*2),\n",
    "            get_dis_block(hidden_dim*2,hidden_dim),\n",
    "            nn.Linear(hidden_dim,1)\n",
    "        )\n",
    "    def forward(self, image):\n",
    "        return self.model(image)\n",
    "    \n",
    "    def get_model_discriminator(self):\n",
    "        return self.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs \n",
    "epochs = 20\n",
    "z_dim = 64 # dimension of the noise vector\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00002\n",
    "# Em dung MNIST dataset\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=False, transform=transforms.ToTensor()),\n",
    "    batch_size= batch_size,\n",
    "    shuffle= True\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(z_dim=z_dim).to(device)\n",
    "gen_optimazation = torch.optim.Adam(generator.parameters(), lr = lr)\n",
    "discriminator = Discriminator().to(device=device)\n",
    "disc_optimazation = torch.optim.Adam(discriminator.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to caculate discriminator's loss and generator's loss\n",
    "def get_gen_loss(generator, discriminator, criterion, num_images, z_dim, device):\n",
    "    # Create noise\n",
    "    fake_noise = get_noise(num_images, z_dim, device)\n",
    "    fake = generator(fake_noise)\n",
    "    disc_fake_pred = discriminator(fake)\n",
    "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "    return gen_loss\n",
    "\n",
    "def get_dis_loss(generator, discriminator, criterion, real, num_images, z_dim, device):\n",
    "    # fake\n",
    "    fake_noise = get_noise(num_images, z_dim=z_dim, device=device)\n",
    "    fake = generator(fake_noise)\n",
    "    disc_fake_predict = discriminator(fake.detach())\n",
    "    disc_fake_loss = criterion(disc_fake_predict, torch.zeros_like(disc_fake_predict))\n",
    "    # real\n",
    "    dis_real_pred = discriminator(real)\n",
    "    disc_real_loss = criterion(dis_real_pred, torch.ones_like(dis_real_pred))\n",
    "    # loss\n",
    "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Batch 0/469                       Loss disc: 0.1400, loss gen: 2.4649\n",
      "Epoch [1/20] Batch 0/469                       Loss disc: 0.1423, loss gen: 2.7555\n",
      "Epoch [2/20] Batch 0/469                       Loss disc: 0.1740, loss gen: 2.5036\n",
      "Epoch [3/20] Batch 0/469                       Loss disc: 0.1115, loss gen: 2.6395\n",
      "Epoch [4/20] Batch 0/469                       Loss disc: 0.0769, loss gen: 4.1252\n",
      "Epoch [5/20] Batch 0/469                       Loss disc: 0.0666, loss gen: 3.6659\n",
      "Epoch [6/20] Batch 0/469                       Loss disc: 0.1209, loss gen: 3.2423\n",
      "Epoch [7/20] Batch 0/469                       Loss disc: 0.1093, loss gen: 3.5754\n",
      "Epoch [8/20] Batch 0/469                       Loss disc: 0.0796, loss gen: 4.1256\n",
      "Epoch [9/20] Batch 0/469                       Loss disc: 0.0955, loss gen: 4.2219\n",
      "Epoch [10/20] Batch 0/469                       Loss disc: 0.0647, loss gen: 3.6646\n",
      "Epoch [11/20] Batch 0/469                       Loss disc: 0.0492, loss gen: 3.7429\n",
      "Epoch [12/20] Batch 0/469                       Loss disc: 0.1092, loss gen: 4.2190\n",
      "Epoch [13/20] Batch 0/469                       Loss disc: 0.1265, loss gen: 3.2360\n",
      "Epoch [14/20] Batch 0/469                       Loss disc: 0.0505, loss gen: 5.0630\n",
      "Epoch [15/20] Batch 0/469                       Loss disc: 0.0891, loss gen: 4.3567\n",
      "Epoch [16/20] Batch 0/469                       Loss disc: 0.0877, loss gen: 3.9402\n",
      "Epoch [17/20] Batch 0/469                       Loss disc: 0.1356, loss gen: 4.4450\n",
      "Epoch [18/20] Batch 0/469                       Loss disc: 0.1091, loss gen: 3.8314\n",
      "Epoch [19/20] Batch 0/469                       Loss disc: 0.0656, loss gen: 4.4421\n"
     ]
    }
   ],
   "source": [
    "cur_step = 0 # so luong buoc huan luyen\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "test_generator = True # Whether the generator should be tested\n",
    "gen_loss = False\n",
    "error = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (real,_) in enumerate(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        # Flatten\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "        \n",
    "        ## Update discriminator\n",
    "        disc_optimazation.zero_grad()\n",
    "        disc_loss = get_dis_loss(generator, discriminator, criterion, real,\n",
    "                                  num_images=cur_batch_size, z_dim=z_dim, device=device)\n",
    "        # update gradien\n",
    "        disc_loss.backward() \n",
    "        # update optimizer\n",
    "        disc_optimazation.step()\n",
    "        if test_generator:\n",
    "            old_generator_weights = generator.gen[0][0].weight.detach().clone()\n",
    "        \n",
    "        # update generator\n",
    "        gen_optimazation.zero_grad()\n",
    "        gen_loss = get_gen_loss(generator, discriminator, criterion, cur_batch_size, z_dim, device)\n",
    "        gen_loss.backward()\n",
    "        gen_optimazation.step()\n",
    "\n",
    "        ## Kiem tra co thay doi weight cua generator hay khong\n",
    "        if test_generator:\n",
    "            try:\n",
    "                assert lr > 0.0000002 or (generator.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n",
    "                assert torch.any(generator.gen[0][0].weight.detach().clone() != old_generator_weights)\n",
    "            except:\n",
    "                error = True\n",
    "                print(\"Runtime tests have failed\")\n",
    "\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{epochs}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                      Loss disc: {disc_loss:.4f}, loss gen: {gen_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake_noise = get_noise(cur_batch_size, z_dim, device)\n",
    "                fake = generator(fake_noise)\n",
    "                img_grid_fake =show_tensor_images(fake)\n",
    "                img_grid_real = show_tensor_images(real)\n",
    "                mean_generator_loss = 0\n",
    "                mean_discriminator_loss = 0\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=cur_step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=cur_step\n",
    "                )\n",
    "                cur_step += 1\n",
    "\n",
    "    # # visualizing result\n",
    "    # if cur_step % display_step == 0 and cur_step > 0:\n",
    "    #     print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "    #     fake_noise = get_noise(cur_batch_size, z_dim, device)\n",
    "    #     fake = generator(fake_noise)\n",
    "        show_tensor_images(fake)\n",
    "    #     show_tensor_images(real)\n",
    "    #     mean_generator_loss = 0\n",
    "    #     mean_discriminator_loss = 0\n",
    "    \n",
    "    # cur_step += 1\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
